Expected artifacts for test run are:
small-ckpt-tune-03082024.pt
small-ckpt-meta-03082024.pt
small-ckpt-hf-03082024.pt
small-ckpt-tune-llama3-05052024.pt
small-ckpt-hf-reward-07122024.pt
small-ckpt-meta-vision-10172024.pt
small-ckpt-hf-vision-10172024.pt
llama3-hf-04232025/config.json
llama3-hf-04232025/generation_config.json
llama3-hf-04232025/model.safetensors
llama3-hf-04232025/model.safetensors.index.json
llama3-hf-04232025/special_tokens_map.json
llama3-hf-04232025/tokenizer.json
llama3-hf-04232025/tokenizer_config.json
config.json
model.safetensors
tokenizer.model
tokenizer_llama3.model
File already exists locally: /tmp/test-artifacts/small-ckpt-tune-03082024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-meta-03082024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-hf-03082024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-tune-llama3-05052024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-hf-reward-07122024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-meta-vision-10172024.pt
File already exists locally: /tmp/test-artifacts/small-ckpt-hf-vision-10172024.pt
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/config.json
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/generation_config.json
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/model.safetensors
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/model.safetensors.index.json
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/special_tokens_map.json
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/tokenizer.json
File already exists locally: /tmp/test-artifacts/llama3-hf-04232025/tokenizer_config.json
File already exists locally: /tmp/test-artifacts/llama3-hf-06112025/config.json
File already exists locally: /tmp/test-artifacts/llama3-hf-06112025/model.safetensors
File already exists locally: /tmp/test-artifacts/tokenizer.model
File already exists locally: /tmp/test-artifacts/tokenizer_llama3.model
============================= test session starts ==============================
platform linux -- Python 3.12.10, pytest-7.4.0, pluggy-1.6.0
rootdir: /mnt/vast/home/ayush/torchtune
configfile: pyproject.toml
plugins: anyio-4.9.0, cov-6.2.1, integration-0.2.3, mock-3.14.1
collected 11 items

tests/recipes/test_full_finetune_single_device.py ........FFF            [100%]

=================================== FAILURES ===================================
____ TestFullFinetuneSingleDeviceRecipe.test_training_state_on_resume[True] ____

self = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027980>
tmpdir = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0')
use_steps = True
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfadf140b0>

    @pytest.mark.integration_test
    @pytest.mark.parametrize("use_steps", [True, False])
    @gpu_test(gpu_count=1)
    def test_training_state_on_resume(self, tmpdir, use_steps, monkeypatch):
        """We want to be sure that now we use steps, we can resume correctly from a checkpoint.
        Once we fully transition to steps, we can remove the test above."""
        # 0. Set up variables
        model_type = "llama3_hf_138m"
        ckpt_dir = Path(CKPT_MODEL_PATHS[model_type])
        model_config = MODEL_TEST_CONFIGS[model_type]
        tokenizer_path = TOKENIZER_PATHS[model_type]
        log_file = gen_log_file_name(tmpdir)
    
        # 1. Train for two epochs, keep 2 checkpoints
        cmd_1 = f"""
        tune run full_finetune_single_device \
            --config llama3/8B_full_single_device \
            output_dir={tmpdir} \
            checkpointer.checkpoint_dir='{ckpt_dir}' \
            checkpointer.checkpoint_files=[model.safetensors]\
            checkpointer.output_dir={tmpdir} \
            checkpointer.keep_last_n_checkpoints=2 \
            tokenizer.path={tokenizer_path} \
            tokenizer.prompt_template=null \
            optimizer_in_bwd=False \
        """.split()
        if use_steps:
            cmd_1.append("save_every_n_steps=2")
            final_ckpt_dir = "step_4"
        else:
            final_ckpt_dir = "epoch_2"
        cmd_1 = cmd_1 + self._get_test_config_overrides() + model_config
    
        monkeypatch.setattr(sys, "argv", cmd_1)
        with pytest.raises(SystemExit, match=""):
            runpy.run_path(TUNE_PATH, run_name="__main__")
    
        # 2. Simulate a crash by deleting the last checkpoint
        shutil.rmtree(os.path.join(tmpdir, final_ckpt_dir))
    
        # 3. Resume training w/ the checkpoint from epoch boundary
        cmd_2 = f"""
        tune run full_finetune_single_device \
            --config llama3/8B_full_single_device \
            output_dir={tmpdir} \
            checkpointer.checkpoint_dir={ckpt_dir} \
            checkpointer.checkpoint_files=[model.safetensors]\
            checkpointer.recipe_checkpoint="recipe_state.pt"\
            checkpointer.keep_last_n_checkpoints=2 \
            checkpointer.output_dir={tmpdir} \
            tokenizer.path={tokenizer_path} \
            tokenizer.prompt_template=null \
            resume_from_checkpoint=True \
            metric_logger.filename={log_file} \
            optimizer_in_bwd=False \
        """.split()
        cmd_2 = cmd_2 + self._get_test_config_overrides() + model_config
        monkeypatch.setattr(sys, "argv", cmd_2)
        with pytest.raises(SystemExit, match=""):
            runpy.run_path(TUNE_PATH, run_name="__main__")
    
        # 4. Make sure loss values match the expected values
        expected_loss_values = self._fetch_expected_loss_values(model_type)[2:]
        loss_values = get_loss_values_from_metric_logger(log_file)
>       torch.testing.assert_close(
            loss_values, expected_loss_values, rtol=1e-4, atol=1e-4
        )
E       AssertionError: Scalars are not close!
E       
E       Expected 11.8903 but got 11.958627700805664.
E       Absolute difference: 0.0683277008056642 (up to 0.0001 allowed)
E       Relative difference: 0.005746507725260439 (up to 0.0001 allowed)
E       
E       The failure occurred for item [0]

ckpt_dir   = PosixPath('/tmp/test-artifacts/llama3-hf-06112025')
cmd_1      = ['torchtune/_cli/tune.py', 'run', 'full_finetune_single_device', '--config', 'llama3/8B_full_single_device', 'output_dir=/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0', ...]
cmd_2      = ['torchtune/_cli/tune.py', 'run', 'full_finetune_single_device', '--config', 'llama3/8B_full_single_device', 'output_dir=/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0', ...]
expected_loss_values = [11.8903, 11.8915]
final_ckpt_dir = 'step_4'
log_file   = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0tmppytest-of-ayushpytest-3test_training_state_on_resume_0.txt'
loss_values = [11.958627700805664, 11.826979637145996]
model_config = ['model._component_=torchtune.models.llama3.llama3', 'model.vocab_size=128_256', 'model.num_layers=2', 'model.num_heads=16', 'model.embed_dim=512', 'model.max_seq_len=1024', ...]
model_type = 'llama3_hf_138m'
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfadf140b0>
self       = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027980>
tmpdir     = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0')
tokenizer_path = '/tmp/test-artifacts/tokenizer_llama3.model'
use_steps  = True

tests/recipes/test_full_finetune_single_device.py:235: AssertionError
----------------------------- Captured stdout call -----------------------------
Writing logs to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/logs/log_1749752543.txt
Writing logs to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0tmppytest-of-ayushpytest-3test_training_state_on_resume_0.txt
----------------------------- Captured stderr call -----------------------------
INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
save_every_n_steps: 2
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO:torchtune.utils._logging:Model is initialized with precision torch.float32.
INFO:torchtune.utils._logging:Memory stats after model init:
	GPU peak memory active: 10.83 GiB
	GPU peak memory alloc: 10.83 GiB
	GPU peak memory reserved: 11.55 GiB
INFO:torchtune.utils._logging:Tokenizer is initialized from file.
INFO:torchtune.utils._logging:Optimizer is initialized.
INFO:torchtune.utils._logging:Loss is initialized.
INFO:torchtune.utils._logging:Learning rate scheduler is initialized.
WARNING:torchtune.utils._logging: Profiling disabled.
INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}
0|0:   0%|          | 0/2 [00:00<?, ?it/s]1|1|Loss: 11.9691:  50%|█████     | 1/2 [00:00<00:00, 25.21it/s]1|2|Loss: 11.8431: 100%|██████████| 2/2 [00:00<00:00, 32.39it/s]INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Getting optimizer state dict...
INFO:torchtune.utils._logging:Getting optimizer state dict took 0.64 secs
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2
INFO:torchtune.utils._logging:Recipe checkpoint of size 1.03 GiB saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/recipe_state.pt
INFO:torchtune.utils._logging:Saving checkpoint took 2.51 secs

2|2:   0%|          | 0/2 [00:00<?, ?it/s][A1|2|Loss: 11.8431: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]

2|3|Loss: 11.9586:  50%|█████     | 1/2 [00:00<00:00, 40.94it/s][A
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:00<00:00, 42.66it/s][AINFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_4
INFO:torchtune.utils._logging:Saving checkpoint took 0.90 secs
INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_4
INFO:torchtune.utils._logging:Saving checkpoint took 0.87 secs
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]
INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
  recipe_checkpoint: recipe_state.pt
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0tmppytest-of-ayushpytest-3test_training_state_on_resume_0.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: true
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO:torchtune.utils._logging:Loading the recipe state using: 
	checkpoint_paths: ['/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/model.safetensors']
	recipe_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/recipe_state.pt
	adapter_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/adapter_model.pt
INFO:torchtune.utils._logging:Model is initialized with precision torch.float32.
INFO:torchtune.utils._logging:Memory stats after model init:
	GPU peak memory active: 11.86 GiB
	GPU peak memory alloc: 11.86 GiB
	GPU peak memory reserved: 13.04 GiB
INFO:torchtune.utils._logging:Tokenizer is initialized from file.
INFO:torchtune.utils._logging:Optimizer is initialized.
INFO:torchtune.utils._logging:Loss is initialized.
INFO:torchtune.utils._logging:Learning rate scheduler is initialized.
WARNING:torchtune.utils._logging: Profiling disabled.
INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}
1|2:   0%|          | 0/2 [00:00<?, ?it/s]2|3|Loss: 11.9586:  50%|█████     | 1/2 [00:00<00:00, 46.43it/s]2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:00<00:00, 47.52it/s]INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.82 secs
INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.88 secs
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]
------------------------------ Captured log call -------------------------------
INFO     torchtune.utils._logging:_utils.py:28 Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
save_every_n_steps: 2
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO     torchtune.utils._logging:full_finetune_single_device.py:427 Model is initialized with precision torch.float32.
INFO     torchtune.utils._logging:memory.py:312 Memory stats after model init:
	GPU peak memory active: 10.83 GiB
	GPU peak memory alloc: 10.83 GiB
	GPU peak memory reserved: 11.55 GiB
INFO     torchtune.utils._logging:full_finetune_single_device.py:262 Tokenizer is initialized from file.
INFO     torchtune.utils._logging:full_finetune_single_device.py:453 Optimizer is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:282 Loss is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:468 Learning rate scheduler is initialized.
WARNING  torchtune.utils._logging:_profiler.py:53  Profiling disabled.
INFO     torchtune.utils._logging:full_finetune_single_device.py:383  Profiler config after instantiation: {'enabled': False}
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpoint_client.py:286 Getting optimizer state dict...
INFO     torchtune.utils._logging:_checkpoint_client.py:308 Getting optimizer state dict took 0.64 secs
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2
INFO     torchtune.utils._logging:_checkpointer.py:1000 Recipe checkpoint of size 1.03 GiB saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/recipe_state.pt
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 2.51 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_4
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.90 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_4
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.87 secs
INFO     torchtune.utils._logging:_utils.py:28 Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
  recipe_checkpoint: recipe_state.pt
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0tmppytest-of-ayushpytest-3test_training_state_on_resume_0.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: true
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO     torchtune.utils._logging:_checkpointer.py:690 Loading the recipe state using: 
	checkpoint_paths: ['/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/model.safetensors']
	recipe_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/recipe_state.pt
	adapter_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/step_2/adapter_model.pt
INFO     torchtune.utils._logging:full_finetune_single_device.py:427 Model is initialized with precision torch.float32.
INFO     torchtune.utils._logging:memory.py:312 Memory stats after model init:
	GPU peak memory active: 11.86 GiB
	GPU peak memory alloc: 11.86 GiB
	GPU peak memory reserved: 13.04 GiB
INFO     torchtune.utils._logging:full_finetune_single_device.py:262 Tokenizer is initialized from file.
INFO     torchtune.utils._logging:full_finetune_single_device.py:453 Optimizer is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:282 Loss is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:468 Learning rate scheduler is initialized.
WARNING  torchtune.utils._logging:_profiler.py:53  Profiling disabled.
INFO     torchtune.utils._logging:full_finetune_single_device.py:383  Profiler config after instantiation: {'enabled': False}
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.82 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_0/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.88 secs
___ TestFullFinetuneSingleDeviceRecipe.test_training_state_on_resume[False] ____

self = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027aa0>
tmpdir = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1')
use_steps = False
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfe7090ec0>

    @pytest.mark.integration_test
    @pytest.mark.parametrize("use_steps", [True, False])
    @gpu_test(gpu_count=1)
    def test_training_state_on_resume(self, tmpdir, use_steps, monkeypatch):
        """We want to be sure that now we use steps, we can resume correctly from a checkpoint.
        Once we fully transition to steps, we can remove the test above."""
        # 0. Set up variables
        model_type = "llama3_hf_138m"
        ckpt_dir = Path(CKPT_MODEL_PATHS[model_type])
        model_config = MODEL_TEST_CONFIGS[model_type]
        tokenizer_path = TOKENIZER_PATHS[model_type]
        log_file = gen_log_file_name(tmpdir)
    
        # 1. Train for two epochs, keep 2 checkpoints
        cmd_1 = f"""
        tune run full_finetune_single_device \
            --config llama3/8B_full_single_device \
            output_dir={tmpdir} \
            checkpointer.checkpoint_dir='{ckpt_dir}' \
            checkpointer.checkpoint_files=[model.safetensors]\
            checkpointer.output_dir={tmpdir} \
            checkpointer.keep_last_n_checkpoints=2 \
            tokenizer.path={tokenizer_path} \
            tokenizer.prompt_template=null \
            optimizer_in_bwd=False \
        """.split()
        if use_steps:
            cmd_1.append("save_every_n_steps=2")
            final_ckpt_dir = "step_4"
        else:
            final_ckpt_dir = "epoch_2"
        cmd_1 = cmd_1 + self._get_test_config_overrides() + model_config
    
        monkeypatch.setattr(sys, "argv", cmd_1)
        with pytest.raises(SystemExit, match=""):
            runpy.run_path(TUNE_PATH, run_name="__main__")
    
        # 2. Simulate a crash by deleting the last checkpoint
        shutil.rmtree(os.path.join(tmpdir, final_ckpt_dir))
    
        # 3. Resume training w/ the checkpoint from epoch boundary
        cmd_2 = f"""
        tune run full_finetune_single_device \
            --config llama3/8B_full_single_device \
            output_dir={tmpdir} \
            checkpointer.checkpoint_dir={ckpt_dir} \
            checkpointer.checkpoint_files=[model.safetensors]\
            checkpointer.recipe_checkpoint="recipe_state.pt"\
            checkpointer.keep_last_n_checkpoints=2 \
            checkpointer.output_dir={tmpdir} \
            tokenizer.path={tokenizer_path} \
            tokenizer.prompt_template=null \
            resume_from_checkpoint=True \
            metric_logger.filename={log_file} \
            optimizer_in_bwd=False \
        """.split()
        cmd_2 = cmd_2 + self._get_test_config_overrides() + model_config
        monkeypatch.setattr(sys, "argv", cmd_2)
        with pytest.raises(SystemExit, match=""):
            runpy.run_path(TUNE_PATH, run_name="__main__")
    
        # 4. Make sure loss values match the expected values
        expected_loss_values = self._fetch_expected_loss_values(model_type)[2:]
        loss_values = get_loss_values_from_metric_logger(log_file)
>       torch.testing.assert_close(
            loss_values, expected_loss_values, rtol=1e-4, atol=1e-4
        )
E       AssertionError: Scalars are not close!
E       
E       Expected 11.8903 but got 11.958627700805664.
E       Absolute difference: 0.0683277008056642 (up to 0.0001 allowed)
E       Relative difference: 0.005746507725260439 (up to 0.0001 allowed)
E       
E       The failure occurred for item [0]

ckpt_dir   = PosixPath('/tmp/test-artifacts/llama3-hf-06112025')
cmd_1      = ['torchtune/_cli/tune.py', 'run', 'full_finetune_single_device', '--config', 'llama3/8B_full_single_device', 'output_dir=/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1', ...]
cmd_2      = ['torchtune/_cli/tune.py', 'run', 'full_finetune_single_device', '--config', 'llama3/8B_full_single_device', 'output_dir=/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1', ...]
expected_loss_values = [11.8903, 11.8915]
final_ckpt_dir = 'epoch_2'
log_file   = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1tmppytest-of-ayushpytest-3test_training_state_on_resume_1.txt'
loss_values = [11.958627700805664, 11.826979637145996]
model_config = ['model._component_=torchtune.models.llama3.llama3', 'model.vocab_size=128_256', 'model.num_layers=2', 'model.num_heads=16', 'model.embed_dim=512', 'model.max_seq_len=1024', ...]
model_type = 'llama3_hf_138m'
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfe7090ec0>
self       = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027aa0>
tmpdir     = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1')
tokenizer_path = '/tmp/test-artifacts/tokenizer_llama3.model'
use_steps  = False

tests/recipes/test_full_finetune_single_device.py:235: AssertionError
----------------------------- Captured stdout call -----------------------------
Writing logs to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/logs/log_1749752551.txt
Writing logs to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1tmppytest-of-ayushpytest-3test_training_state_on_resume_1.txt
----------------------------- Captured stderr call -----------------------------
INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO:torchtune.utils._logging:Model is initialized with precision torch.float32.
INFO:torchtune.utils._logging:Memory stats after model init:
	GPU peak memory active: 12.37 GiB
	GPU peak memory alloc: 12.37 GiB
	GPU peak memory reserved: 13.54 GiB
INFO:torchtune.utils._logging:Tokenizer is initialized from file.
INFO:torchtune.utils._logging:Optimizer is initialized.
INFO:torchtune.utils._logging:Loss is initialized.
INFO:torchtune.utils._logging:Learning rate scheduler is initialized.
WARNING:torchtune.utils._logging: Profiling disabled.
INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}
0|0:   0%|          | 0/2 [00:00<?, ?it/s]1|1|Loss: 11.9691:  50%|█████     | 1/2 [00:00<00:00, 29.34it/s]1|2|Loss: 11.8431: 100%|██████████| 2/2 [00:00<00:00, 36.84it/s]INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Getting optimizer state dict...
INFO:torchtune.utils._logging:Getting optimizer state dict took 0.56 secs
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1
INFO:torchtune.utils._logging:Recipe checkpoint of size 1.03 GiB saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/recipe_state.pt
INFO:torchtune.utils._logging:Saving checkpoint took 2.23 secs

2|2:   0%|          | 0/2 [00:00<?, ?it/s][A1|2|Loss: 11.8431: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]

2|3|Loss: 11.9586:  50%|█████     | 1/2 [00:00<00:00, 49.22it/s][A
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:00<00:00, 48.80it/s][AINFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.82 secs
INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.86 secs
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:01<00:00,  1.14it/s]
INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
  recipe_checkpoint: recipe_state.pt
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1tmppytest-of-ayushpytest-3test_training_state_on_resume_1.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: true
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO:torchtune.utils._logging:Loading the recipe state using: 
	checkpoint_paths: ['/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/model.safetensors']
	recipe_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/recipe_state.pt
	adapter_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/adapter_model.pt
INFO:torchtune.utils._logging:Model is initialized with precision torch.float32.
INFO:torchtune.utils._logging:Memory stats after model init:
	GPU peak memory active: 12.37 GiB
	GPU peak memory alloc: 12.37 GiB
	GPU peak memory reserved: 13.54 GiB
INFO:torchtune.utils._logging:Tokenizer is initialized from file.
INFO:torchtune.utils._logging:Optimizer is initialized.
INFO:torchtune.utils._logging:Loss is initialized.
INFO:torchtune.utils._logging:Learning rate scheduler is initialized.
WARNING:torchtune.utils._logging: Profiling disabled.
INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}
1|2:   0%|          | 0/2 [00:00<?, ?it/s]2|3|Loss: 11.9586:  50%|█████     | 1/2 [00:00<00:00, 47.14it/s]2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:00<00:00, 47.46it/s]INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.81 secs
INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 0.87 secs
2|4|Loss: 11.8270: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]
------------------------------ Captured log call -------------------------------
INFO     torchtune.utils._logging:_utils.py:28 Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO     torchtune.utils._logging:full_finetune_single_device.py:427 Model is initialized with precision torch.float32.
INFO     torchtune.utils._logging:memory.py:312 Memory stats after model init:
	GPU peak memory active: 12.37 GiB
	GPU peak memory alloc: 12.37 GiB
	GPU peak memory reserved: 13.54 GiB
INFO     torchtune.utils._logging:full_finetune_single_device.py:262 Tokenizer is initialized from file.
INFO     torchtune.utils._logging:full_finetune_single_device.py:453 Optimizer is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:282 Loss is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:468 Learning rate scheduler is initialized.
WARNING  torchtune.utils._logging:_profiler.py:53  Profiling disabled.
INFO     torchtune.utils._logging:full_finetune_single_device.py:383  Profiler config after instantiation: {'enabled': False}
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpoint_client.py:286 Getting optimizer state dict...
INFO     torchtune.utils._logging:_checkpoint_client.py:308 Getting optimizer state dict took 0.56 secs
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1
INFO     torchtune.utils._logging:_checkpointer.py:1000 Recipe checkpoint of size 1.03 GiB saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/recipe_state.pt
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 2.23 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.82 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.86 secs
INFO     torchtune.utils._logging:_utils.py:28 Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 2
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  keep_last_n_checkpoints: 2
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
  recipe_checkpoint: recipe_state.pt
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1tmppytest-of-ayushpytest-3test_training_state_on_resume_1.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: true
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO     torchtune.utils._logging:_checkpointer.py:690 Loading the recipe state using: 
	checkpoint_paths: ['/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/model.safetensors']
	recipe_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/recipe_state.pt
	adapter_checkpoint: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_1/adapter_model.pt
INFO     torchtune.utils._logging:full_finetune_single_device.py:427 Model is initialized with precision torch.float32.
INFO     torchtune.utils._logging:memory.py:312 Memory stats after model init:
	GPU peak memory active: 12.37 GiB
	GPU peak memory alloc: 12.37 GiB
	GPU peak memory reserved: 13.54 GiB
INFO     torchtune.utils._logging:full_finetune_single_device.py:262 Tokenizer is initialized from file.
INFO     torchtune.utils._logging:full_finetune_single_device.py:453 Optimizer is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:282 Loss is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:468 Learning rate scheduler is initialized.
WARNING  torchtune.utils._logging:_profiler.py:53  Profiling disabled.
INFO     torchtune.utils._logging:full_finetune_single_device.py:383  Profiler config after instantiation: {'enabled': False}
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.81 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_1/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 0.87 secs
_ TestFullFinetuneSingleDeviceRecipe.test_training_state_on_resume_with_async_checkpointing[llama3_hf_138m] _

self = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027c80>
tmpdir = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfc81fb080>
model_ckpt = 'llama3_hf_138m'

    @pytest.mark.integration_test
    @gpu_test(gpu_count=1)
    @pytest.mark.parametrize(
        "model_ckpt",
        [
            ("llama3_hf_138m"),
        ],
    )
    def test_training_state_on_resume_with_async_checkpointing(
        self, tmpdir, monkeypatch, model_ckpt
    ):
        """Test whether the recipe state is correctly updated on resume. Since this
        is model agnostic, we should run this on the small model only. The test
        consists of three stages:
            - Train a model for 2 epochs
            - Resume training after epoch 1
            - Make sure final loss matches the expected value of a model successfully resumed from a ckpt
        """
    
        ckpt_dir = Path(CKPT_MODEL_PATHS[model_ckpt])
        tokenizer_path = Path(TOKENIZER_PATHS[model_ckpt])
        first_log_file = gen_log_file_name(tmpdir, suffix="first")
    
        # Train for two epochs
        cmd_1 = f"""
        tune run full_finetune_single_device \
            --config llama3/8B_full_single_device \
            batch_size=8 \
            output_dir={tmpdir} \
            checkpointer.checkpoint_dir='{ckpt_dir}' \
            checkpointer.checkpoint_files=[model.safetensors]\
            checkpointer.output_dir={tmpdir} \
            enable_async_checkpointing=True\
            tokenizer.path='{tokenizer_path}' \
            tokenizer.prompt_template=null \
            metric_logger.filename={first_log_file} \
            optimizer_in_bwd=False \
        """.split()
    
        model_config = MODEL_TEST_CONFIGS[model_ckpt]
        cmd_1 = cmd_1 + self._get_test_config_overrides() + model_config
    
        monkeypatch.setattr(sys, "argv", cmd_1)
        with pytest.raises(SystemExit, match=""):
            runpy.run_path(TUNE_PATH, run_name="__main__")
    
        # Sanity check that the loss values are expected for the initial run
        expected_loss_values = self._fetch_expected_loss_values(model_ckpt)
        loss_values = get_loss_values_from_metric_logger(first_log_file)
        torch.testing.assert_close(
            loss_values, expected_loss_values, rtol=1e-4, atol=1e-4
        )
    
        # delete latest checkpoint dir to make sure we are resuming from the right one
>       shutil.rmtree(os.path.join(tmpdir, "step_4"))

ckpt_dir   = PosixPath('/tmp/test-artifacts/llama3-hf-06112025')
cmd_1      = ['torchtune/_cli/tune.py', 'run', 'full_finetune_single_device', '--config', 'llama3/8B_full_single_device', 'batch_size=8', ...]
expected_loss_values = [11.8934, 11.9444, 11.8903, 11.8915]
first_log_file = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2tmppytest-of-ayushpytest-3test_training_state_on_resume_2first.txt'
loss_values = [11.893411636352539, 11.944428443908691, 11.890344619750977, 11.891547203063965]
model_ckpt = 'llama3_hf_138m'
model_config = ['model._component_=torchtune.models.llama3.llama3', 'model.vocab_size=128_256', 'model.num_layers=2', 'model.num_heads=16', 'model.embed_dim=512', 'model.max_seq_len=1024', ...]
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fcfc81fb080>
self       = <tests.recipes.test_full_finetune_single_device.TestFullFinetuneSingleDeviceRecipe object at 0x7fcffe027c80>
tmpdir     = local('/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2')
tokenizer_path = PosixPath('/tmp/test-artifacts/tokenizer_llama3.model')

tests/recipes/test_full_finetune_single_device.py:293: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/shutil.py:759: in rmtree
    _rmtree_safe_fd(stack, onexc)
        dir_fd     = None
        ignore_errors = False
        onerror    = None
        onexc      = <function rmtree.<locals>.onexc at 0x7fcfc800dbc0>
        path       = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'
        stack      = []
../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/shutil.py:703: in _rmtree_safe_fd
    onexc(func, path, err)
        dirfd      = None
        func       = <built-in function lstat>
        name       = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'
        onexc      = <function rmtree.<locals>.onexc at 0x7fcfc800dbc0>
        orig_entry = None
        path       = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'
        stack      = []
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

stack = [], onexc = <function rmtree.<locals>.onexc at 0x7fcfc800dbc0>

    def _rmtree_safe_fd(stack, onexc):
        # Each stack item has four elements:
        # * func: The first operation to perform: os.lstat, os.close or os.rmdir.
        #   Walking a directory starts with an os.lstat() to detect symlinks; in
        #   this case, func is updated before subsequent operations and passed to
        #   onexc() if an error occurs.
        # * dirfd: Open file descriptor, or None if we're processing the top-level
        #   directory given to rmtree() and the user didn't supply dir_fd.
        # * path: Path of file to operate upon. This is passed to onexc() if an
        #   error occurs.
        # * orig_entry: os.DirEntry, or None if we're processing the top-level
        #   directory given to rmtree(). We used the cached stat() of the entry to
        #   save a call to os.lstat() when walking subdirectories.
        func, dirfd, path, orig_entry = stack.pop()
        name = path if orig_entry is None else orig_entry.name
        try:
            if func is os.close:
                os.close(dirfd)
                return
            if func is os.rmdir:
                os.rmdir(name, dir_fd=dirfd)
                return
    
            # Note: To guard against symlink races, we use the standard
            # lstat()/open()/fstat() trick.
            assert func is os.lstat
            if orig_entry is None:
>               orig_st = os.lstat(name, dir_fd=dirfd)
E               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'

dirfd      = None
func       = <built-in function lstat>
name       = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'
onexc      = <function rmtree.<locals>.onexc at 0x7fcfc800dbc0>
orig_entry = None
path       = '/tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/step_4'
stack      = []

../.local/share/uv/python/cpython-3.12.10-linux-x86_64-gnu/lib/python3.12/shutil.py:669: FileNotFoundError
----------------------------- Captured stdout call -----------------------------
Writing logs to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2tmppytest-of-ayushpytest-3test_training_state_on_resume_2first.txt
----------------------------- Captured stderr call -----------------------------
INFO:torchtune.utils._logging:Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 8
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
enable_async_checkpointing: true
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2tmppytest-of-ayushpytest-3test_training_state_on_resume_2first.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO:torchtune.utils._logging:Model is initialized with precision torch.float32.
INFO:torchtune.utils._logging:Memory stats after model init:
	GPU peak memory active: 12.88 GiB
	GPU peak memory alloc: 12.88 GiB
	GPU peak memory reserved: 14.29 GiB
INFO:torchtune.utils._logging:Tokenizer is initialized from file.
INFO:torchtune.utils._logging:Optimizer is initialized.
INFO:torchtune.utils._logging:Loss is initialized.
INFO:torchtune.utils._logging:Learning rate scheduler is initialized.
WARNING:torchtune.utils._logging: Profiling disabled.
INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}
0|0:   0%|          | 0/2 [00:00<?, ?it/s]1|1|Loss: 11.8934:  50%|█████     | 1/2 [00:00<00:00, 24.75it/s]1|2|Loss: 11.9444: 100%|██████████| 2/2 [00:00<00:00, 31.98it/s]INFO:torchtune.utils._logging:Saving checkpoint asynchronously. Retrieving full state dict...
INFO:torchtune.utils._logging:Rank 0: Trainer was blocked for 0.99 seconds for checkpointing to finish...
INFO:torchtune.utils._logging:Saving asynchronous checkpoint took 0.99 secs

2|2:   0%|          | 0/2 [00:00<?, ?it/s][A1|2|Loss: 11.9444: 100%|██████████| 2/2 [00:01<00:00,  1.90it/s]

2|2:  50%|█████     | 1/2 [00:00<00:00,  4.20it/s][A
2|3|Loss: 11.8903:  50%|█████     | 1/2 [00:00<00:00,  4.20it/s][A
2|3|Loss: 11.8903: 100%|██████████| 2/2 [00:00<00:00,  5.86it/s][A
2|4|Loss: 11.8915: 100%|██████████| 2/2 [00:00<00:00,  5.86it/s][AINFO:torchtune.utils._logging:Saving checkpoint asynchronously. Retrieving full state dict...
INFO:torchtune.utils._logging:Rank 0: previous checkpoint has not finished. Checkpointing frequency is too high. Waiting...
INFO:torchtune.utils._logging:Rank 0: Checkpoint is saved asynchronously to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_1 successfully.
INFO:torchtune.utils._logging:Rank 0: waited 0.48 seconds for previous checkpoint to finish
INFO:torchtune.utils._logging:Rank 0: Trainer was blocked for 0.87 seconds for checkpointing to finish...
INFO:torchtune.utils._logging:Saving asynchronous checkpoint took 1.36 secs
INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO:torchtune.utils._logging:Rank 0: Checkpoint is saved asynchronously to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_2 successfully.
INFO:torchtune.utils._logging:Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_2
INFO:torchtune.utils._logging:Saving checkpoint took 1.56 secs
2|4|Loss: 11.8915: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
------------------------------ Captured log call -------------------------------
INFO     torchtune.utils._logging:_utils.py:28 Running FullFinetuneRecipeSingleDevice with resolved config:

batch_size: 8
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: /tmp/test-artifacts/llama3-hf-06112025
  checkpoint_files:
  - model.safetensors
  model_type: LLAMA3
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2
  recipe_checkpoint: null
clip_grad_norm: null
compile: false
dataset:
  _component_: torchtune.datasets.alpaca_dataset
  data_files: /mnt/vast/home/ayush/torchtune/tests/assets/alpaca_tiny.json
  packed: false
  source: json
  split: train
  train_on_input: false
device: cuda
dtype: fp32
enable_activation_checkpointing: false
enable_activation_offloading: false
enable_async_checkpointing: true
epochs: 2
gradient_accumulation_steps: 1
log_every_n_steps: 1
log_level: INFO
log_peak_memory_stats: true
loss:
  _component_: torchtune.modules.loss.LinearCrossEntropyLoss
lr_scheduler:
  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup
  num_cycles: 0
  num_warmup_steps: 0
max_steps_per_epoch: 2
metric_logger:
  _component_: torchtune.training.metric_logging.DiskLogger
  filename: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2tmppytest-of-ayushpytest-3test_training_state_on_resume_2first.txt
  log_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/logs
model:
  _component_: torchtune.models.llama3.llama3
  embed_dim: 512
  max_seq_len: 1024
  norm_eps: 1.0e-05
  num_heads: 16
  num_kv_heads: 8
  num_layers: 2
  vocab_size: 128256
optimizer:
  _component_: torch.optim.AdamW
  lr: 2.0e-05
optimizer_in_bwd: false
output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2
profiler:
  _component_: torchtune.training.setup_torch_profiler
  active_steps: 2
  cpu: true
  cuda: true
  enabled: false
  num_cycles: 1
  output_dir: /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/profiling_outputs
  profile_memory: false
  record_shapes: true
  wait_steps: 5
  warmup_steps: 3
  with_flops: false
  with_stack: false
resume_from_checkpoint: false
seed: 9
shuffle: true
tokenizer:
  _component_: torchtune.models.llama3.llama3_tokenizer
  max_seq_len: null
  path: /tmp/test-artifacts/tokenizer_llama3.model
  prompt_template: null

INFO     torchtune.utils._logging:full_finetune_single_device.py:427 Model is initialized with precision torch.float32.
INFO     torchtune.utils._logging:memory.py:312 Memory stats after model init:
	GPU peak memory active: 12.88 GiB
	GPU peak memory alloc: 12.88 GiB
	GPU peak memory reserved: 14.29 GiB
INFO     torchtune.utils._logging:full_finetune_single_device.py:262 Tokenizer is initialized from file.
INFO     torchtune.utils._logging:full_finetune_single_device.py:453 Optimizer is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:282 Loss is initialized.
INFO     torchtune.utils._logging:full_finetune_single_device.py:468 Learning rate scheduler is initialized.
WARNING  torchtune.utils._logging:_profiler.py:53  Profiling disabled.
INFO     torchtune.utils._logging:full_finetune_single_device.py:383  Profiler config after instantiation: {'enabled': False}
INFO     torchtune.utils._logging:_checkpoint_client.py:155 Saving checkpoint asynchronously. Retrieving full state dict...
INFO     torchtune.utils._logging:_checkpointer.py:1432 Rank 0: Trainer was blocked for 0.99 seconds for checkpointing to finish...
INFO     torchtune.utils._logging:_checkpoint_client.py:191 Saving asynchronous checkpoint took 0.99 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:155 Saving checkpoint asynchronously. Retrieving full state dict...
INFO     torchtune.utils._logging:_checkpointer.py:1392 Rank 0: previous checkpoint has not finished. Checkpointing frequency is too high. Waiting...
INFO     torchtune.utils._logging:_checkpointer.py:1411 Rank 0: Checkpoint is saved asynchronously to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_1 successfully.
INFO     torchtune.utils._logging:_checkpointer.py:1398 Rank 0: waited 0.48 seconds for previous checkpoint to finish
INFO     torchtune.utils._logging:_checkpointer.py:1432 Rank 0: Trainer was blocked for 0.87 seconds for checkpointing to finish...
INFO     torchtune.utils._logging:_checkpoint_client.py:191 Saving asynchronous checkpoint took 1.36 secs
INFO     torchtune.utils._logging:_checkpoint_client.py:255 Saving checkpoint. This may take some time. Retrieving full model state dict...
INFO     torchtune.utils._logging:_checkpointer.py:1411 Rank 0: Checkpoint is saved asynchronously to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_2 successfully.
INFO     torchtune.utils._logging:_checkpointer.py:882 Model checkpoint saved to /tmp/pytest-of-ayush/pytest-3/test_training_state_on_resume_2/epoch_2
INFO     torchtune.utils._logging:_checkpoint_client.py:349 Saving checkpoint took 1.56 secs
=============================== warnings summary ===============================
tests/recipes/test_full_finetune_single_device.py: 13 warnings
  /mnt/vast/home/ayush/torchtune/torchtune/datasets/_alpaca.py:78: DeprecationWarning: train_on_input is deprecated and will be removed in a future release. Please use masking_strategy instead.You should replace train_on_input=True with masking_strategy='train_on_all', and train_on_input=False with masking_strategy='train_on_assistant'.For backwards compatibility, if you pass both train_on_input and masking_strategy, the value of masking_strategy will be ignored until torchtune 0.7. 
    message_transform = AlpacaToMessages(

tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_loss[llama3/8B_full_single_device-llama3_hf_138m-2-4-False-True]
  /mnt/vast/home/ayush/torchtune/recipes/full_finetune_single_device.py:628: FutureWarning: scale_grads is deprecated and will be removed in future versions. Please use `scale_grads_` instead.
    training.scale_grads(self._model, 1.0 / num_tokens)

tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_training_state_on_resume_with_async_checkpointing[llama3_hf_138m]
  /mnt/vast/home/ayush/torchtune/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:167: UserWarning: torch.distributed is disabled, unavailable or uninitialized, assuming the intent is to save in a single process.
    warnings.warn(

tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_training_state_on_resume_with_async_checkpointing[llama3_hf_138m]
  /mnt/vast/home/ayush/torchtune/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:111: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
    if tensor.storage().size() != tensor.numel():

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_training_state_on_resume[True]
FAILED tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_training_state_on_resume[False]
FAILED tests/recipes/test_full_finetune_single_device.py::TestFullFinetuneSingleDeviceRecipe::test_training_state_on_resume_with_async_checkpointing[llama3_hf_138m]
============= 3 failed, 8 passed, 16 warnings in 75.70s (0:01:15) ==============
